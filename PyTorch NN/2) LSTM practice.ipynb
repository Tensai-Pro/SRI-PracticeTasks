{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObJvoe6zAO1vchJPfZsj3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tensai-Pro/SRI-PracticeTasks/blob/master/PyTorch%20NN/2)%20LSTM%20practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNw6Mdn7e_W4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 5\n",
        "hidden_dim = 10\n",
        "n_layers = 1\n",
        "\n",
        "lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)"
      ],
      "metadata": {
        "id": "SlGZsVk9fYSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "seq_len = 1\n",
        "\n",
        "input = torch.randn(batch_size, seq_len, input_dim)\n",
        "print('input:', input)\n",
        "print('input size:', input.size(), '\\n')\n",
        "\n",
        "# aka short-term memory like RNN\n",
        "hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
        "print('hidden_state:', hidden_state)\n",
        "\n",
        "# aka long-term memory\n",
        "cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
        "print('cell_state:', cell_state, '\\n')\n",
        "\n",
        "hidden = (hidden_state, cell_state)\n",
        "print('hidden size:', hidden[0].size(), hidden[1].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu8LH9ohgSVm",
        "outputId": "77ed4b8e-41dd-4616-e5ff-a87fddc566ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: tensor([[[ 1.1451, -1.3795, -0.9568,  0.3689,  2.0626]]])\n",
            "input size: torch.Size([1, 1, 5]) \n",
            "\n",
            "hidden_state: tensor([[[-1.9935,  0.2174,  0.7200,  1.2299, -0.1605, -1.1076, -0.0368,\n",
            "          -0.0402, -0.2583,  0.7759]]])\n",
            "cell_state: tensor([[[ 0.2231, -0.1037,  0.2102,  0.2070, -0.7071,  0.2560,  1.3563,\n",
            "           0.8705, -0.8090,  0.2590]]]) \n",
            "\n",
            "hidden size: torch.Size([1, 1, 10]) torch.Size([1, 1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, hidden = lstm_layer(input, hidden)\n",
        "print('output shape:', output.shape)\n",
        "print('hidden:', hidden)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4TUyGlhizMC",
        "outputId": "9c236558-2c6c-45c6-a38b-10003625562a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output shape: torch.Size([1, 1, 10])\n",
            "hidden: (tensor([[[ 0.2011,  0.2540, -0.0937, -0.2799, -0.3517, -0.0228, -0.0273,\n",
            "           0.2518,  0.1124, -0.1598]]], grad_fn=<StackBackward0>), tensor([[[ 0.4135,  0.8069, -0.2394, -0.5959, -1.0656, -0.0451, -0.0488,\n",
            "           0.4450,  0.2407, -0.5188]]], grad_fn=<StackBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing sequence length (ok for LSTM unlike RNN)\n",
        "seq_len = 3\n",
        "input = torch.randn(batch_size, seq_len, input_dim)\n",
        "output, hidden = lstm_layer(input, hidden)\n",
        "print(output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbCwyZ8BjlqK",
        "outputId": "40610b7b-bc53-41ea-aa4a-0f38961692a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 10])\n",
            "tensor([[[-0.1084,  0.0264,  0.1322, -0.0481, -0.2250, -0.0824,  0.1412,\n",
            "           0.2178, -0.0852, -0.2946],\n",
            "         [-0.1012,  0.0635,  0.1645, -0.0733, -0.2002, -0.1513,  0.1872,\n",
            "           0.2198, -0.1244, -0.2799],\n",
            "         [-0.1244,  0.0812,  0.1804, -0.0512, -0.1963, -0.1761,  0.2531,\n",
            "           0.2684, -0.1896, -0.2306]]], grad_fn=<TransposeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = output.squeeze()[-1, :]\n",
        "print(output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEgr5p8Bku4-",
        "outputId": "9388f9d4-29dd-4d56-9e81-1943348aac8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10])\n",
            "tensor([-0.1244,  0.0812,  0.1804, -0.0512, -0.1963, -0.1761,  0.2531,  0.2684,\n",
            "        -0.1896, -0.2306], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    }
  ]
}