# (07.05.2023)
ИЗМЕНЕНИЯ:
- **Word2Vec**
  - Добавлен стемминг в функцию предобработки.
  - Вся пунктуация удаляется методом gensim.simple_preprocess().
  - Эксперимент с атрибутом sample (раздел "Атрибут sample") провалился.
    - Я ещё нигде не видела, чтобы в w2v использовали фильтрацию, отсеевая слишком частые слова. В документации gensim нашла только этот атрибут. Сказано, что он должен опускать рандомные часто встречаемые слова с указанной вероятностью; пробовала много разных значений, — словарь оставался той же длины, так что эксперимент провалился. 
- **fastText**:
  - Добавлена аж лемматизация.
  - Решена проблема с низкой точностью при изначальном supervised обучении. 
    - В функуцию векторизации отправлялась целая строка сплошным текстом, и внутри цикла обрабатывалась каждая буква, а не токен. Ошибка исправлена разделением каждого предложения на токены перед отправлением в функцию.
  - Испытано обучение fastText без учителя (раздел "Unsupervised fastText").
    - Точность классификаторов с использованием получившихся таким образом векторов значительно выше.
- **BERT**: 
  - изменений нет, ещё не разобралась с использованием токенов [CLS].
- Ограничивать длину текста не стала, так как в этом датасете используются не сами новостные статьи, а только их описание, как краткая сводка. Так что там примерно токенов 30 в среднем в каждом тексте и получается.
